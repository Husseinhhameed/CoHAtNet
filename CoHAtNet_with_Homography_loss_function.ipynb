{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNLD1ja4JENIV6df49hWpJt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Husseinhhameed/CoHAtNet/blob/main/CoHAtNet_with_Homography_loss_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CoHAtNet with 7Scenes dataset"
      ],
      "metadata": {
        "id": "CohvurYu4Iy_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GlKs_Vl7G8N",
        "outputId": "e33ebba3-dfa6-44f8-aa07-ed2782bf430f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to access the dataset stored there\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required packages:\n",
        "1. 'transforms3d' for quaternion manipulations\n",
        "2. 'einops' for tensor manipulation and rearranging operations\n",
        "3. 'kornia' for geometry conversions and other computer vision tasks"
      ],
      "metadata": {
        "id": "knkyC0D64VcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transforms3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPFfb7Uo7JEh",
        "outputId": "d562eaa0-6855-4b2f-c3ea-234ae6e49e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transforms3d\n",
            "  Downloading transforms3d-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from transforms3d) (1.26.4)\n",
            "Downloading transforms3d-0.4.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transforms3d\n",
            "Successfully installed transforms3d-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkodD1DD7KOf",
        "outputId": "9a022dec-1f64-4048-d585-5947f5d2fd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kornia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL9UpcUB8TCi",
        "outputId": "dcff1f82-b2fa-4690-ed78-8f7f019f3db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kornia\n",
            "  Downloading kornia-0.7.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia)\n",
            "  Downloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia) (24.1)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia) (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n",
            "Downloading kornia-0.7.3-py2.py3-none-any.whl (833 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.3/833.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kornia-rs, kornia\n",
            "Successfully installed kornia-0.7.3 kornia-rs-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all necessary libraries and modules for data processing, model creation, and training\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Compose, RandomHorizontalFlip, RandomRotation, ToTensor\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "from torchvision.utils import make_grid\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "import transforms3d.quaternions as txq\n",
        "import matplotlib.pyplot as plt\n",
        "from kornia.geometry.conversions import quaternion_to_rotation_matrix\n",
        "import pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OerTZIzw7LiC",
        "outputId": "daefd64d-4bc7-40d5-d145-de12e3b73ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Global Homography Loss Function\n",
        "class GlobalHomographyLoss(torch.nn.Module):\n",
        "    def __init__(self, xmin, xmax, device='cpu'):\n",
        "        \"\"\"\n",
        "        `xmin` is the minimum distance of observations across all frames.\n",
        "        `xmax` is the maximum distance of observations across all frames.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # `xmin` is the minimum distance of observations in all frames\n",
        "        xmin = torch.tensor(xmin, dtype=torch.float32, device=device)\n",
        "\n",
        "        # `xmax` is the maximum distance of observations in all frames\n",
        "        xmax = torch.tensor(xmax, dtype=torch.float32, device=device)\n",
        "\n",
        "        # `B_weight` and `C_weight` are the weights of matrices A and B computed from `xmin` and `xmax`\n",
        "        self.B_weight = torch.log(xmin / xmax) / (xmax - xmin)\n",
        "        self.C_weight = xmin * xmax\n",
        "\n",
        "        # `c_n` is the normal vector of the plane inducing the homographies in the ground-truth camera frame\n",
        "        self.c_n = torch.tensor([0, 0, -1], dtype=torch.float32, device=device).view(3, 1)\n",
        "\n",
        "        # `eye` is the (3, 3) identity matrix\n",
        "        self.eye = torch.eye(3, device=device)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        A, B, C = compute_ABC(batch['w_t_c'], batch['c_R_w'], batch['w_t_chat'], batch['chat_R_w'], self.c_n, self.eye)\n",
        "\n",
        "        error = A + B * self.B_weight + C / self.C_weight\n",
        "        error = error.diagonal(dim1=1, dim2=2).sum(dim=1).mean()\n",
        "        return error"
      ],
      "metadata": {
        "id": "zlomPsMg7Ok0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_ABC(w_t_c, c_R_w, w_t_chat, chat_R_w, c_n, eye):\n",
        "    \"\"\"\n",
        "    Computes A, B, and C matrix given estimated and ground truth poses\n",
        "    and normal vector n.\n",
        "    `w_t_c` and `w_t_chat` must have shape (batch_size, 3, 1).\n",
        "    `c_R_w` and `chat_R_w` must have shape (batch_size, 3, 3).\n",
        "    `n` must have shape (3, 1).\n",
        "    `eye` is the (3, 3) identity matrix on the proper device.\n",
        "    \"\"\"\n",
        "    # Ensure all inputs are float32\n",
        "    w_t_c = w_t_c.float()\n",
        "    c_R_w = c_R_w.float()\n",
        "    w_t_chat = w_t_chat.float()\n",
        "    chat_R_w = chat_R_w.float()\n",
        "    c_n = c_n.float()\n",
        "    eye = eye.float()\n",
        "\n",
        "    chat_t_c = chat_R_w @ (w_t_c - w_t_chat)\n",
        "    chat_R_c = chat_R_w @ c_R_w.transpose(1, 2)\n",
        "\n",
        "    A = eye - chat_R_c\n",
        "    C = c_n @ chat_t_c.transpose(1, 2)\n",
        "    B = C @ A\n",
        "    A = A @ A.transpose(1, 2)\n",
        "    B = B + B.transpose(1, 2)\n",
        "    C = C @ C.transpose(1, 2)\n",
        "\n",
        "    return A, B, C\n"
      ],
      "metadata": {
        "id": "qgCrlMn-7YfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_transformation_matrix(translation, quaternion):\n",
        "    \"\"\"\n",
        "    Converts a translation vector and quaternion to a 4x4 transformation matrix.\n",
        "    \"\"\"\n",
        "    # Convert quaternion to rotation matrix\n",
        "    R = quaternion_to_rotation_matrix(quaternion)\n",
        "\n",
        "    # Create a 4x4 transformation matrix\n",
        "    T = torch.eye(4)  # Initialize as 4x4 identity matrix\n",
        "    T[:3, :3] = R  # Set the top-left 3x3 submatrix as the rotation matrix\n",
        "    T[:3, 3] = translation  # Set the top-right 3x1 subvector as the translation vector\n",
        "\n",
        "    return T\n"
      ],
      "metadata": {
        "id": "VEbKfsB67b-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_poses(data_dir, seqs, train=True, real=False, vo_lib='orbslam'):\n",
        "    \"\"\"\n",
        "    Loads and processes pose data from the given directory.\n",
        "\n",
        "    Args:\n",
        "        data_dir (str): The root directory containing the dataset.\n",
        "        seqs (list): List of sequences to load poses from.\n",
        "        train (bool): If True, compute and save statistics; otherwise, load them.\n",
        "        real (bool): If True, use real-world poses; otherwise, use synthetic ones.\n",
        "        vo_lib (str): Visual odometry library used ('orbslam', 'libviso2', etc.).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Processed and normalized poses.\n",
        "    \"\"\"\n",
        "    ps = {}  # Dictionary to store pose data for each sequence\n",
        "    vo_stats = {}  # Dictionary to store VO statistics for each sequence\n",
        "    all_poses = []  # List to collect all pose data\n",
        "\n",
        "    for seq in seqs:\n",
        "        seq_dir = os.path.join(data_dir, seq)\n",
        "        p_filenames = [n for n in os.listdir(seq_dir) if n.find('pose') >= 0]\n",
        "\n",
        "        if real:\n",
        "            # Load poses from a real-world dataset\n",
        "            pose_file = os.path.join(data_dir, f'{vo_lib}_poses', seq)\n",
        "            pss = np.loadtxt(pose_file)\n",
        "            frame_idx = pss[:, 0].astype(int)\n",
        "            if vo_lib == 'libviso2':\n",
        "                frame_idx -= 1\n",
        "            ps[seq] = pss[:, 1:13]\n",
        "            vo_stats_filename = os.path.join(seq_dir, f'{vo_lib}_vo_stats.pkl')\n",
        "            with open(vo_stats_filename, 'rb') as f:\n",
        "                vo_stats[seq] = pickle.load(f)\n",
        "        else:\n",
        "            # Load poses from synthetic dataset\n",
        "            frame_idx = np.array(range(len(p_filenames)), dtype=int)\n",
        "            pss = [np.loadtxt(os.path.join(seq_dir, f'frame-{i:06d}.pose.txt')).flatten()[:12]\n",
        "                   for i in frame_idx\n",
        "                   if os.path.exists(os.path.join(seq_dir, f'frame-{i:06d}.pose.txt'))]\n",
        "            ps[seq] = np.asarray(pss)\n",
        "            vo_stats[seq] = {'R': np.eye(3), 't': np.zeros(3), 's': 1}  # Default VO stats for synthetic data\n",
        "\n",
        "        all_poses.append(ps[seq])\n",
        "\n",
        "    all_poses = np.vstack(all_poses)\n",
        "    pose_stats_filename = os.path.join(data_dir, 'pose_stats.txt')\n",
        "\n",
        "    # Compute or load statistics for normalization\n",
        "    if train and not real:\n",
        "        mean_t = np.mean(all_poses[:, [3, 7, 11]], axis=0)\n",
        "        std_t = np.std(all_poses[:, [3, 7, 11]], axis=0)\n",
        "        np.savetxt(pose_stats_filename, np.vstack((mean_t, std_t)), fmt='%8.7f')\n",
        "    else:\n",
        "        mean_t, std_t = np.loadtxt(pose_stats_filename)\n",
        "\n",
        "    # Process and normalize poses\n",
        "    processed_poses = []\n",
        "    for seq in seqs:\n",
        "        pss = process_poses(poses_in=ps[seq], mean_t=mean_t, std_t=std_t,\n",
        "                            align_R=vo_stats[seq]['R'], align_t=vo_stats[seq]['t'],\n",
        "                            align_s=vo_stats[seq]['s'])\n",
        "        processed_poses.append(pss)\n",
        "\n",
        "    return np.vstack(processed_poses)\n",
        "\n",
        "\n",
        "def process_poses(poses_in, mean_t, std_t, align_R, align_t, align_s):\n",
        "    \"\"\"\n",
        "    Aligns and normalizes poses.\n",
        "\n",
        "    Args:\n",
        "        poses_in (np.ndarray): Input poses to process.\n",
        "        mean_t (np.ndarray): Mean translation for normalization.\n",
        "        std_t (np.ndarray): Standard deviation of translation for normalization.\n",
        "        align_R (np.ndarray): Rotation matrix for alignment.\n",
        "        align_t (np.ndarray): Translation vector for alignment.\n",
        "        align_s (float): Scaling factor for alignment.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Processed poses.\n",
        "    \"\"\"\n",
        "    poses_out = np.zeros((len(poses_in), 7))\n",
        "    poses_out[:, 0:3] = poses_in[:, [3, 7, 11]]  # Translation components\n",
        "\n",
        "    # Align and process rotation\n",
        "    for i in range(len(poses_out)):\n",
        "        R = poses_in[i].reshape((3, 4))[:3, :3]\n",
        "        q = txq.mat2quat(np.dot(align_R, R))\n",
        "        q *= np.sign(q[0])  # Constrain to hemisphere\n",
        "        poses_out[i, 3:] = q  # Keep the quaternion as 4D\n",
        "        t = poses_out[i, :3] - align_t\n",
        "        poses_out[i, :3] = align_s * np.dot(align_R, t[:, np.newaxis]).squeeze()\n",
        "\n",
        "    # Normalize translation\n",
        "    poses_out[:, :3] -= mean_t\n",
        "    poses_out[:, :3] /= std_t\n",
        "\n",
        "    return poses_out"
      ],
      "metadata": {
        "id": "wMJLcKle7d4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformation for the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "pL3rqaIg98h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "id": "irpGfGJI45j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "class FireDataset(Dataset):\n",
        "    def __init__(self, root_dir, xmin_percentile=0.025, xmax_percentile=0.975, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.xmin_percentile = xmin_percentile\n",
        "        self.xmax_percentile = xmax_percentile\n",
        "\n",
        "        # Load sequences and samples\n",
        "        self.seqs = [seq for seq in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, seq))]\n",
        "        self.samples = self._load_samples()\n",
        "\n",
        "        # Check for precomputed depth statistics\n",
        "        stats_file = os.path.join(root_dir, 'depth_stats.json')\n",
        "        if os.path.exists(stats_file):\n",
        "            with open(stats_file, 'r') as f:\n",
        "                stats = json.load(f)\n",
        "                self.global_xmin = stats['global_xmin']\n",
        "                self.global_xmax = stats['global_xmax']\n",
        "        else:\n",
        "            # Compute depth statistics using a subset\n",
        "            self.global_depths = self._compute_global_depths()\n",
        "            self.global_xmin = np.percentile(self.global_depths, self.xmin_percentile * 100)\n",
        "            self.global_xmax = np.percentile(self.global_depths, self.xmax_percentile * 100)\n",
        "            with open(stats_file, 'w') as f:\n",
        "                json.dump({'global_xmin': self.global_xmin, 'global_xmax': self.global_xmax}, f)\n",
        "            del self.global_depths  # Free memory\n",
        "\n",
        "        # Load and process poses\n",
        "        self.processed_poses = self._load_processed_poses()\n",
        "\n",
        "        # Ensure consistency between samples and processed poses\n",
        "        min_length = min(len(self.samples), self.processed_poses.shape[0])\n",
        "        self.samples = self.samples[:min_length]\n",
        "        self.processed_poses = self.processed_poses[:min_length]\n",
        "\n",
        "    def _load_samples(self):\n",
        "        \"\"\"\n",
        "        Loads all sample file paths from the dataset directory.\n",
        "        \"\"\"\n",
        "        samples = []\n",
        "        for seq_folder in self.seqs:\n",
        "            seq_path = os.path.join(self.root_dir, seq_folder)\n",
        "            color_files = sorted([f for f in os.listdir(seq_path) if f.endswith('.color.png')])\n",
        "            depth_files = sorted([f for f in os.listdir(seq_path) if f.endswith('.depth.png')])\n",
        "            pose_files = sorted([f for f in os.listdir(seq_path) if f.endswith('.pose.txt')])\n",
        "\n",
        "            for color_file, depth_file, pose_file in zip(color_files, depth_files, pose_files):\n",
        "                samples.append((os.path.join(seq_path, color_file),\n",
        "                                os.path.join(seq_path, depth_file),\n",
        "                                os.path.join(seq_path, pose_file)))\n",
        "        return samples\n",
        "\n",
        "    def _compute_global_depths(self):\n",
        "        \"\"\"\n",
        "        Computes global depth statistics by loading a subset of depth images.\n",
        "        \"\"\"\n",
        "        num_samples = len(self.samples)\n",
        "        sample_indices = random.sample(range(num_samples), min(100, num_samples))  # Use a subset of images\n",
        "        all_depths = []\n",
        "\n",
        "        for idx in tqdm(sample_indices, desc=\"Computing global depths\"):\n",
        "            _, depth_path, _ = self.samples[idx]\n",
        "            depth_image = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)\n",
        "            valid_depths = depth_image[depth_image > 0]\n",
        "            all_depths.extend(valid_depths.flatten())\n",
        "\n",
        "        all_depths = np.array(all_depths)\n",
        "        return all_depths\n",
        "\n",
        "    def _load_processed_poses(self):\n",
        "        \"\"\"\n",
        "        Loads and processes pose data from the given directory.\n",
        "        \"\"\"\n",
        "        return load_and_process_poses(self.root_dir, self.seqs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self.processed_poses):\n",
        "            raise IndexError(f\"Index {idx} out of bounds for processed poses of size {len(self.processed_poses)}\")\n",
        "\n",
        "        color_path, depth_path, _ = self.samples[idx]\n",
        "\n",
        "        color_image = cv2.imread(color_path, cv2.IMREAD_COLOR)\n",
        "        depth_image = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)\n",
        "        pose_matrix = self.processed_poses[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            color_image = self.transform(color_image)\n",
        "            depth_image = (depth_image / depth_image.max() * 255).astype(np.uint8)\n",
        "            depth_image = self.transform(depth_image)\n",
        "\n",
        "        return color_image, depth_image, pose_matrix\n"
      ],
      "metadata": {
        "id": "Ys1gHcTR7ifa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CoHAtNet Model"
      ],
      "metadata": {
        "id": "aXx9w3ru5B-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "\n",
        "def conv_3x3_bn(inp, oup, image_size, downsample=False):\n",
        "    stride = 1 if downsample == False else 2\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        nn.GELU()\n",
        "    )\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn, norm):\n",
        "        super().__init__()\n",
        "        self.norm = norm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "\n",
        "class SE(nn.Module):\n",
        "    def __init__(self, inp, oup, expansion=0.25):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(oup, int(inp * expansion), bias=False),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(int(inp * expansion), oup, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class MBConv(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, downsample=False, expansion=4):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample\n",
        "        stride = 1 if self.downsample == False else 2\n",
        "        hidden_dim = int(inp * expansion)\n",
        "\n",
        "        if self.downsample:\n",
        "            self.pool = nn.MaxPool2d(3, 2, 1)\n",
        "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "\n",
        "        if expansion == 1:\n",
        "            self.conv = nn.Sequential(\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride,\n",
        "                          1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pw\n",
        "                # down-sample in the first conv\n",
        "                nn.Conv2d(inp, hidden_dim, 1, stride, 0, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, 1, 1,\n",
        "                          groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                SE(inp, hidden_dim),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "\n",
        "        self.conv = PreNorm(inp, self.conv, nn.BatchNorm2d)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.downsample:\n",
        "            return self.proj(self.pool(x)) + self.conv(x)\n",
        "        else:\n",
        "            return x + self.conv(x)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == inp)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        # parameter table of relative position bias\n",
        "        self.relative_bias_table = nn.Parameter(\n",
        "            torch.zeros((2 * self.ih - 1) * (2 * self.iw - 1), heads))\n",
        "\n",
        "        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))\n",
        "        coords = torch.flatten(torch.stack(coords), 1)\n",
        "        relative_coords = coords[:, :, None] - coords[:, None, :]\n",
        "\n",
        "        relative_coords[0] += self.ih - 1\n",
        "        relative_coords[1] += self.iw - 1\n",
        "        relative_coords[0] *= 2 * self.iw - 1\n",
        "        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n",
        "        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n",
        "        self.register_buffer(\"relative_index\", relative_index)\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)\n",
        "        self.to_qkv = nn.Linear(inp, inner_dim * 3, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, oup),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = map(lambda t: rearrange(\n",
        "            t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        # Use \"gather\" for more efficiency on GPUs\n",
        "        relative_bias = self.relative_bias_table.gather(\n",
        "            0, self.relative_index.repeat(1, self.heads))\n",
        "        relative_bias = rearrange(\n",
        "            relative_bias, '(h w) c -> 1 c h w', h=self.ih*self.iw, w=self.ih*self.iw)\n",
        "        dots = dots + relative_bias\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out = self.to_out(out)\n",
        "        return out\n",
        "\n",
        "class HAttention(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == inp)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        # parameter table of relative position bias\n",
        "        self.relative_bias_table = nn.Parameter(\n",
        "            torch.zeros((2 * self.ih - 1) * (2 * self.iw - 1), heads))\n",
        "\n",
        "        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))\n",
        "        coords = torch.flatten(torch.stack(coords), 1)\n",
        "        relative_coords = coords[:, :, None] - coords[:, None, :]\n",
        "\n",
        "        relative_coords[0] += self.ih - 1\n",
        "        relative_coords[1] += self.iw - 1\n",
        "        relative_coords[0] *= 2 * self.iw - 1\n",
        "        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n",
        "        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n",
        "        self.register_buffer(\"relative_index\", relative_index)\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)\n",
        "        self.to_qk = nn.Linear(inp, inner_dim * 2, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "#            nn.Linear(inner_dim, oup),\n",
        "            nn.Linear(oup, oup),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, mbconv):\n",
        "        qk = self.to_qk(x).chunk(2, dim=-1)\n",
        "        q, k = map(lambda t: rearrange(\n",
        "            t, 'b n (h d) -> b h n d', h=self.heads), qk)\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        # Use \"gather\" for more efficiency on GPUs\n",
        "        relative_bias = self.relative_bias_table.gather(\n",
        "            0, self.relative_index.repeat(1, self.heads))\n",
        "        relative_bias = rearrange(\n",
        "            relative_bias, '(h w) c -> 1 c h w', h=self.ih*self.iw, w=self.ih*self.iw)\n",
        "        dots = dots + relative_bias\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "        v = rearrange(mbconv, 'b c ih iw -> b (ih iw) c')\n",
        "        v = rearrange(v, 'b n (h c) -> b h n c', h=self.heads)\n",
        "\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out = self.to_out(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, downsample=False, dropout=0.):\n",
        "        super().__init__()\n",
        "        hidden_dim = int(inp * 4)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "        self.downsample = downsample\n",
        "\n",
        "        if self.downsample:\n",
        "            self.pool1 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.pool2 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "\n",
        "        self.attn = Attention(inp, oup, image_size, heads, dim_head, dropout)\n",
        "        self.ff = FeedForward(oup, hidden_dim, dropout)\n",
        "\n",
        "        self.attn = nn.Sequential(\n",
        "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
        "            PreNorm(inp, self.attn, nn.LayerNorm),\n",
        "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "        )\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
        "            PreNorm(oup, self.ff, nn.LayerNorm),\n",
        "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.downsample:\n",
        "            x = self.proj(self.pool1(x)) + self.attn(self.pool2(x))\n",
        "        else:\n",
        "            x = x + self.attn(x)\n",
        "        x = x + self.ff(x)\n",
        "        return x\n",
        "\n",
        "class HTransformer(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, downsample=False, dropout=0.):\n",
        "        super().__init__()\n",
        "        hidden_dim = int(inp * 4)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "        self.downsample = downsample\n",
        "        self.layer_norm = nn.LayerNorm(inp)\n",
        "        self.MBConv = MBConv(inp, oup, image_size, downsample)\n",
        "\n",
        "        if self.downsample:\n",
        "            self.pool1 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.pool2 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "\n",
        "        self.attn = HAttention(inp, oup, image_size, heads, dim_head, dropout)\n",
        "        self.ff = FeedForward(oup, hidden_dim, dropout)\n",
        "\n",
        "#        self.attn = nn.Sequential(\n",
        "#            Rearrange('b c ih iw -> b (ih iw) c'),\n",
        "#            PreNorm(inp, self.attn, nn.LayerNorm),\n",
        "#            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "#        )\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
        "            PreNorm(oup, self.ff, nn.LayerNorm),\n",
        "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        mbconv = self.MBConv(x)\n",
        "        if self.downsample:\n",
        "            pool1 = self.pool2(x)\n",
        "            pool1 = rearrange(pool1, 'b c ih iw -> b (ih iw) c')\n",
        "            norm1 = self.layer_norm(pool1)\n",
        "            attn1 = self.attn(norm1, mbconv)\n",
        "            attn1 = rearrange(attn1, 'b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "            out1 = self.proj(self.pool1(x)) + attn1\n",
        "#            x = self.proj(self.pool1(x)) + self.attn(self.pool2(x), y)\n",
        "        else:\n",
        "            xx = rearrange(x, 'b c ih iw -> b (ih iw) c')\n",
        "            norm1 = self.layer_norm(xx)\n",
        "            attn1 = self.attn(norm1, mbconv)\n",
        "            attn1 = rearrange(attn1, 'b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "            out1 = x + attn1\n",
        "\n",
        "#            x = x + self.attn(x,y)\n",
        "        x = out1 + self.ff(out1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CoHAtNet(nn.Module):\n",
        "    def __init__(self, image_size, in_channels, num_blocks, channels, num_classes=1000, block_types=['C', 'C', 'H', 'H']):\n",
        "        super().__init__()\n",
        "        ih, iw = image_size\n",
        "        block = {'C': MBConv, 'T': Transformer, 'H': HTransformer}\n",
        "\n",
        "        self.s0 = self._make_layer(\n",
        "            conv_3x3_bn, in_channels, channels[0], num_blocks[0], (ih // 2, iw // 2))\n",
        "        self.s1 = self._make_layer(\n",
        "            block[block_types[0]], channels[0], channels[1], num_blocks[1], (ih // 4, iw // 4))\n",
        "        self.s2 = self._make_layer(\n",
        "            block[block_types[1]], channels[1], channels[2], num_blocks[2], (ih // 8, iw // 8))\n",
        "        self.s3 = self._make_layer(\n",
        "            block[block_types[2]], channels[2], channels[3], num_blocks[3], (ih // 16, iw // 16))\n",
        "        self.s4 = self._make_layer(\n",
        "            block[block_types[3]], channels[3], channels[4], num_blocks[4], (ih // 32, iw // 32))\n",
        "\n",
        "        self.pool = nn.AvgPool2d(ih // 32, 1)\n",
        "        hidden_dim = 1024\n",
        "        self.fc1 = nn.Linear(channels[-1] * 2, hidden_dim)\n",
        "        self.relu = nn.ReLU()  # Activation function between dense layers\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)  # Another dense layer\n",
        "        self.fc3 = nn.Linear(hidden_dim // 2, 7)  # Final output layer adjusted to target size (e.g., 6 for 6DoF pose)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.s0(x)\n",
        "        x = self.s1(x)\n",
        "        x = self.s2(x)\n",
        "        x = self.s3(x)\n",
        "        x = self.s4(x)\n",
        "\n",
        "        x = self.pool(x).view(-1, x.shape[1])\n",
        "\n",
        "        # Concatenation might be necessary depending on model specifics; assuming you meant *2 in channels\n",
        "        x = torch.cat((x, x), dim=1)  # Concatenation for expanding feature dimension\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, inp, oup, depth, image_size):\n",
        "        layers = nn.ModuleList([])\n",
        "        for i in range(depth):\n",
        "            if i == 0:\n",
        "                layers.append(block(inp, oup, image_size, downsample=True))\n",
        "            else:\n",
        "                layers.append(block(oup, oup, image_size))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def cohatnet_0():\n",
        "    num_blocks = [2, 2, 3, 5, 2]            # L\n",
        "    channels = [64, 96, 192, 384, 768]      # D\n",
        "    return CoHAtNet((256, 256), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def cohatnet_1():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [64, 96, 192, 384, 768]      # D\n",
        "    return CoHAtNet((256, 256), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def cohatnet_2():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [128, 128, 256, 512, 1024]   # D\n",
        "    return CoHAtNet((256, 256), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def cohatnet_3():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [192, 192, 384, 768, 1536]   # D\n",
        "    return CoHAtNet((256, 256), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def cohatnet_4():\n",
        "    num_blocks = [2, 2, 12, 28, 2]          # L\n",
        "    channels = [192, 192, 384, 768, 1536]   # D\n",
        "    return CoHAtNet((256, 256), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    img = torch.randn(1, 3, 256, 256)\n",
        "\n",
        "    net = cohatnet_0()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = cohatnet_1()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = cohatnet_2()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = cohatnet_3()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = cohatnet_4()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOzKNrCW7uRA",
        "outputId": "8af2d052-fb88-4cdc-b3a8-460b68f316eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 7]) 34337023\n",
            "torch.Size([1, 7]) 62756935\n",
            "torch.Size([1, 7]) 108877575\n",
            "torch.Size([1, 7]) 238862151\n",
            "torch.Size([1, 7]) 411054007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_to_device(batch, device):\n",
        "    \"\"\"\n",
        "    If `device` is not 'cpu', moves all data in batch to the GPU.\n",
        "    \"\"\"\n",
        "    if device != 'cpu':\n",
        "        for key, value in batch.items():\n",
        "            if isinstance(value, torch.Tensor):\n",
        "                batch[key] = value.to(device)\n",
        "            elif isinstance(value[0], torch.Tensor):\n",
        "                for index_value, value_value in enumerate(value):\n",
        "                    value[index_value] = value_value.to(device)\n",
        "    return batch\n"
      ],
      "metadata": {
        "id": "aQnAORqq70oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "K4sycc1T5J26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    root_dir = '/content/drive/MyDrive/fire'\n",
        "\n",
        "    # Check for GPU availability and define device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Using device: {device}')\n",
        "\n",
        "    dataset = FireDataset(root_dir=root_dir, transform=transform)\n",
        "\n",
        "    # Instantiate the Global Homography Loss with computed xmin and xmax\n",
        "    global_loss_fn = GlobalHomographyLoss(xmin=dataset.global_xmin, xmax=dataset.global_xmax, device=device)\n",
        "\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    num_epochs = 200  # Define the number of epochs\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f'Fold {fold + 1}')\n",
        "\n",
        "        train_sampler = SubsetRandomSampler(train_idx)\n",
        "        val_sampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "        train_loader = DataLoader(dataset, batch_size=8, sampler=train_sampler, num_workers=0, pin_memory=False)\n",
        "        val_loader = DataLoader(dataset, batch_size=8, sampler=val_sampler, num_workers=0, pin_memory=False)\n",
        "\n",
        "        model = cohatnet_0().to(device)  # Use a smaller model\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=4, factor=0.1)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "\n",
        "            for color_images, depth_images, poses in tqdm(train_loader):\n",
        "                color_images, poses = color_images.to(device), poses.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(color_images)\n",
        "\n",
        "                # Convert predicted outputs to a transformation matrix\n",
        "                pred_translation = outputs[:, :3]\n",
        "                pred_quaternion = outputs[:, 3:]\n",
        "                pred_quaternion = F.normalize(pred_quaternion, p=2, dim=-1)\n",
        "\n",
        "                # Prepare batch for loss computation\n",
        "                batch = {\n",
        "                    'w_t_c': pred_translation.unsqueeze(-1),\n",
        "                    'c_R_w': quaternion_to_rotation_matrix(pred_quaternion),\n",
        "                    'w_t_chat': poses[:, :3].unsqueeze(-1),  # Corrected for 2D tensor\n",
        "                    'chat_R_w': quaternion_to_rotation_matrix(poses[:, 3:])  # Convert quaternion to rotation matrix\n",
        "                }\n",
        "\n",
        "                loss = global_loss_fn(batch)\n",
        "                loss.backward()  # This was missing in your original code\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for color_images, depth_images, poses in val_loader:\n",
        "                    color_images, poses = color_images.to(device), poses.to(device)\n",
        "                    outputs = model(color_images)\n",
        "\n",
        "                    # Convert predicted outputs to a transformation matrix\n",
        "                    pred_translation = outputs[:, :3]\n",
        "                    pred_quaternion = outputs[:, 3:]\n",
        "                    pred_quaternion = F.normalize(pred_quaternion, p=2, dim=-1)\n",
        "\n",
        "                    # Prepare batch for loss computation\n",
        "                    batch = {\n",
        "                        'w_t_c': pred_translation.unsqueeze(-1),\n",
        "                        'c_R_w': quaternion_to_rotation_matrix(pred_quaternion),\n",
        "                        'w_t_chat': poses[:, :3].unsqueeze(-1),\n",
        "                        'chat_R_w': quaternion_to_rotation_matrix(poses[:, 3:])\n",
        "                    }\n",
        "\n",
        "                    loss = global_loss_fn(batch)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            print(f'Epoch {epoch + 1}, Train Loss: {avg_train_loss}, Val Loss: {val_loss / len(val_loader)}')\n",
        "            torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fl-9oIJc73Z_",
        "outputId": "7648be22-367a-436f-972d-bd8ec7ccbfd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing global depths: 100%|██████████| 100/100 [01:12<00:00,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [05:48<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 0.28966043850407003, Val Loss: 0.061404002234339713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train Loss: 0.05517053067684174, Val Loss: 0.020966893546283245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Train Loss: 0.01994513839657884, Val Loss: 0.013791554421186448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Train Loss: 0.013040020476328209, Val Loss: 0.01220401294529438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train Loss: 0.009332132398267277, Val Loss: 0.004363562890794128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:17<00:00,  2.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Train Loss: 0.006698154580080881, Val Loss: 0.005998032758943736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Train Loss: 0.006755618319439236, Val Loss: 0.0075409399345517155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Train Loss: 0.005799728282145224, Val Loss: 0.005000838788691908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Train Loss: 0.005651691219536587, Val Loss: 0.008120902669616044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:17<00:00,  2.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 0.008296324118273333, Val Loss: 0.0036229212873149664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:17<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Train Loss: 0.004169012782222125, Val Loss: 0.002718017071019858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:17<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Train Loss: 0.0041259924430050885, Val Loss: 0.002445554316509515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Train Loss: 0.004985432543035131, Val Loss: 0.0031223570613656193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Train Loss: 0.004502105439023581, Val Loss: 0.003793821844737977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Train Loss: 0.0037666001472098287, Val Loss: 0.004481421572854742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Train Loss: 0.004961377410800196, Val Loss: 0.004588748482055962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Train Loss: 0.004256206968129846, Val Loss: 0.005437889975728467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Train Loss: 0.0013946942752227187, Val Loss: 0.000838925012940308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Train Loss: 0.0007650216982801794, Val Loss: 0.0007096901026670821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Train Loss: 0.0006464843022695277, Val Loss: 0.000672351041721413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Train Loss: 0.0005473318728036247, Val Loss: 0.0006513437852845527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Train Loss: 0.00048745564205091794, Val Loss: 0.0005564966070232913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Train Loss: 0.00043516101588465973, Val Loss: 0.0005161964565922972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Train Loss: 0.00041815752658294516, Val Loss: 0.0005486478992679622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Train Loss: 0.0003895926962286467, Val Loss: 0.0004977232425881084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Train Loss: 0.0003642234454309801, Val Loss: 0.0005567090134718456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Train Loss: 0.0003655134683685901, Val Loss: 0.0005258312652586028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Train Loss: 0.0003332148087247333, Val Loss: 0.0005678973942121957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Train Loss: 0.0003266304897442751, Val Loss: 0.0005237789470993448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Train Loss: 0.0003431609715698869, Val Loss: 0.0004391001258045435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31, Train Loss: 0.0003081712245875678, Val Loss: 0.0004081197742198128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32, Train Loss: 0.0002955283303526812, Val Loss: 0.0004084293937194161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Train Loss: 0.00027446967891592067, Val Loss: 0.00039189012903079857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34, Train Loss: 0.00027376657224522207, Val Loss: 0.00040203152762842366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35, Train Loss: 0.00028891818028569104, Val Loss: 0.0005373179825255648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36, Train Loss: 0.00027408153597207273, Val Loss: 0.00048351854740758427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37, Train Loss: 0.0003198873953442671, Val Loss: 0.0005239129197434523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38, Train Loss: 0.00025672135960121524, Val Loss: 0.0005824770154140424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39, Train Loss: 0.0001433073320367839, Val Loss: 0.0003066783979011234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40, Train Loss: 0.00012046929994539823, Val Loss: 0.00030559879531210754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41, Train Loss: 0.00011481007823931578, Val Loss: 0.00029702277686737943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42, Train Loss: 0.00011115898300886328, Val Loss: 0.0002931000849639531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43, Train Loss: 0.00010498817058760324, Val Loss: 0.000293645779020153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44, Train Loss: 0.00010310187893537659, Val Loss: 0.00030562567968445365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Train Loss: 0.00010193783834438363, Val Loss: 0.00029751417081570254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:15<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46, Train Loss: 0.00010041446727882431, Val Loss: 0.00030898382028681225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47, Train Loss: 9.751858067374997e-05, Val Loss: 0.0003038774505694164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48, Train Loss: 8.869182417583943e-05, Val Loss: 0.0002921200510900235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:12<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Train Loss: 8.848019878769264e-05, Val Loss: 0.00028662819582677914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:12<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Train Loss: 8.484399143526388e-05, Val Loss: 0.0002834280090610264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51, Train Loss: 8.868386806625495e-05, Val Loss: 0.00029049731136183255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:12<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52, Train Loss: 8.694727259353385e-05, Val Loss: 0.00028090614658140113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53, Train Loss: 8.539836013369494e-05, Val Loss: 0.00029709742411796467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:12<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54, Train Loss: 8.669940633808437e-05, Val Loss: 0.00028075890506443105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55, Train Loss: 8.366520105937525e-05, Val Loss: 0.00028438938556064387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56, Train Loss: 8.830341005705122e-05, Val Loss: 0.00028489213655120694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57, Train Loss: 8.785802533111563e-05, Val Loss: 0.00029471170477336273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:14<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58, Train Loss: 8.54581623843842e-05, Val Loss: 0.00028429915648302994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59, Train Loss: 8.439149025434744e-05, Val Loss: 0.000279785948805511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60, Train Loss: 8.898781783500453e-05, Val Loss: 0.00027728431261493826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61, Train Loss: 8.610055870121869e-05, Val Loss: 0.0002876526644831756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62, Train Loss: 8.220547785185772e-05, Val Loss: 0.0002787130964134121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63, Train Loss: 8.546814889996312e-05, Val Loss: 0.00029720003964030185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64, Train Loss: 8.162748848917544e-05, Val Loss: 0.00029051899931801015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65, Train Loss: 8.335763810919161e-05, Val Loss: 0.00027929023788601624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66, Train Loss: 8.756708922192047e-05, Val Loss: 0.0002805597509723157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67, Train Loss: 8.425872676525614e-05, Val Loss: 0.00028162707094452343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68, Train Loss: 8.181689377124712e-05, Val Loss: 0.0002834495989372954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:14<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69, Train Loss: 8.751683202717686e-05, Val Loss: 0.00028554001277370845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70, Train Loss: 8.218158139243314e-05, Val Loss: 0.0002821707821203745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:13<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71, Train Loss: 8.262765845756803e-05, Val Loss: 0.0002925941268040333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:12<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72, Train Loss: 8.352555722467514e-05, Val Loss: 0.00028565310029080135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:12<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73, Train Loss: 8.58175928624405e-05, Val Loss: 0.0002821707205293933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:12<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74, Train Loss: 8.486149583404767e-05, Val Loss: 0.0002891923008428421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:12<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75, Train Loss: 8.211733795178589e-05, Val Loss: 0.00028501071290520485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:12<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76, Train Loss: 8.199272831461712e-05, Val Loss: 0.0002835678413975984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:12<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77, Train Loss: 8.167128793502342e-05, Val Loss: 0.00028060624455974906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [02:12<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78, Train Loss: 8.135043708534795e-05, Val Loss: 0.00028023886210576165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 110/400 [00:36<01:36,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2d38bcfbfc62>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This was missing in your original code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CoHatNet- Cambridge Landmarks"
      ],
      "metadata": {
        "id": "hnReu0z3u6_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L6yslSwkaDU",
        "outputId": "fd1fab5f-10c1-4d24-975d-e0fbe140cee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transforms3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mag2z8khkeRm",
        "outputId": "2814d35f-371b-4925-a8dc-ec632c370e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transforms3d\n",
            "  Downloading transforms3d-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from transforms3d) (1.26.4)\n",
            "Downloading transforms3d-0.4.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transforms3d\n",
            "Successfully installed transforms3d-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okvOiDSxko8I",
        "outputId": "bfb4c440-33c4-45ac-ca80-c944ac2f7df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kornia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CroVja-vksEX",
        "outputId": "86c5a5f0-7597-42d7-e067-c013751c8f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kornia\n",
            "  Downloading kornia-0.7.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia)\n",
            "  Downloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia) (24.1)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia) (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n",
            "Downloading kornia-0.7.3-py2.py3-none-any.whl (833 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.3/833.3 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kornia-rs, kornia\n",
            "Successfully installed kornia-0.7.3 kornia-rs-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Compose, RandomHorizontalFlip, RandomRotation, ToTensor\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "from torchvision.utils import make_grid\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "import transforms3d.quaternions as txq\n",
        "import matplotlib.pyplot as plt\n",
        "from kornia.geometry.conversions import quaternion_to_rotation_matrix\n",
        "import pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZGsZ6G_kw9j",
        "outputId": "30847d45-5588-4ecc-8c0c-a318c0156ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Xmin & Xmax"
      ],
      "metadata": {
        "id": "9ukni8aI5iNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import kornia  # For quaternion to rotation matrix conversion\n",
        "\n",
        "# Dataset class adjusted for your dataset structure\n",
        "class VisualLandmarkDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.gt_data = self._load_ground_truth()\n",
        "\n",
        "        # Load samples\n",
        "        self.samples = self._load_samples()\n",
        "\n",
        "        print(f\"Number of samples: {len(self.samples)}\")\n",
        "\n",
        "    def _load_ground_truth(self):\n",
        "        gt_path = os.path.join(self.root_dir, 'GT.txt')\n",
        "        gt_data = {}\n",
        "        with open(gt_path, 'r') as f:\n",
        "            lines = f.readlines()[2:]  # Skip the first two lines (header)\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) < 8:\n",
        "                    continue  # Skip malformed lines\n",
        "                image_path = parts[0]  # Image path relative to the dataset root\n",
        "                pose = np.array([float(x) for x in parts[1:]])\n",
        "                gt_data[os.path.normpath(image_path)] = pose\n",
        "        return gt_data\n",
        "\n",
        "    def _load_samples(self):\n",
        "        samples = []\n",
        "        for seq_folder in os.listdir(self.root_dir):\n",
        "            seq_path = os.path.join(self.root_dir, seq_folder)\n",
        "            if os.path.isdir(seq_path):\n",
        "                image_files = sorted([f for f in os.listdir(seq_path) if f.endswith('.png')])\n",
        "                for image_file in image_files:\n",
        "                    image_path = os.path.join(seq_folder, image_file)\n",
        "                    norm_image_path = os.path.normpath(image_path)\n",
        "                    if norm_image_path in self.gt_data:\n",
        "                        full_image_path = os.path.join(self.root_dir, image_path)\n",
        "                        samples.append((full_image_path, self.gt_data[norm_image_path]))\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        color_path, pose = self.samples[idx]\n",
        "        color_image = cv2.imread(color_path, cv2.IMREAD_COLOR)\n",
        "        translation = pose[:3]\n",
        "        quaternion = pose[3:]\n",
        "        pose_matrix = np.concatenate([translation, quaternion])\n",
        "        if self.transform:\n",
        "            color_image = self.transform(color_image)\n",
        "        return color_image, torch.tensor(pose_matrix, dtype=torch.float32)\n",
        "\n",
        "# Function to parse reconstruction.nvm and extract 3D world points (w_P)\n",
        "def parse_nvm_file(nvm_file_path):\n",
        "    scene_coordinates = []\n",
        "    with open(nvm_file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        n_views = int(lines[2])  # Number of images\n",
        "        n_points = int(lines[2 + n_views + 2])  # Number of 3D points\n",
        "\n",
        "        for i in range(3 + n_views + 3, 3 + n_views + 3 + n_points):\n",
        "            point_data = lines[i].strip().split()[:3]  # Extract only the first 3 values (XYZ coordinates)\n",
        "\n",
        "            # Ensure the line contains valid 3D coordinates (3 floating-point numbers)\n",
        "            if len(point_data) != 3:\n",
        "                print(f\"Skipping invalid point on line {i}: {lines[i].strip()}\")\n",
        "                continue  # Skip this line if it doesn't have exactly 3 values\n",
        "\n",
        "            try:\n",
        "                w_P = np.array([float(coord) for coord in point_data])\n",
        "                scene_coordinates.append(w_P)  # Append valid 3D coordinates to scene_coordinates\n",
        "            except ValueError:\n",
        "                print(f\"Skipping malformed point data on line {i}: {lines[i].strip()}\")\n",
        "                continue  # Skip lines with invalid float conversions\n",
        "\n",
        "    if len(scene_coordinates) == 0:\n",
        "        raise ValueError(\"No valid 3D points found in the reconstruction.nvm file.\")\n",
        "\n",
        "    return torch.tensor(scene_coordinates, dtype=torch.float32)\n",
        "\n",
        "# Function to calculate xmin and xmax for each image in the dataset\n",
        "def compute_xmin_xmax(w_P, c_R_w, w_t_c, xmin_percentile=0.025, xmax_percentile=0.975):\n",
        "    # Project world points to camera frame\n",
        "    c_P = c_R_w @ (w_P.T - w_t_c)\n",
        "\n",
        "    # Depth values from the Z-axis (third column of c_P)\n",
        "    depths = c_P[2, :]\n",
        "\n",
        "    # Filter depths based on valid range (as in original code)\n",
        "    valid_depths = depths[(depths > 0.2) & (depths < 1000)]\n",
        "\n",
        "    # Sort valid depths to compute percentiles\n",
        "    sorted_depths = torch.sort(valid_depths).values\n",
        "\n",
        "    # Compute xmin and xmax using specified percentiles\n",
        "    xmin = sorted_depths[int(xmin_percentile * (sorted_depths.shape[0] - 1))]\n",
        "    xmax = sorted_depths[int(xmax_percentile * (sorted_depths.shape[0] - 1))]\n",
        "\n",
        "    return xmin, xmax\n",
        "\n",
        "# Convert quaternion to rotation matrix using Kornia\n",
        "def quaternion_to_rotation_matrix(quaternion):\n",
        "    \"\"\"\n",
        "    Converts a quaternion to a 3x3 rotation matrix using Kornia.\n",
        "    Kornia expects quaternions in (batch_size, 4) format.\n",
        "    \"\"\"\n",
        "    # Ensure the quaternion is in the correct format: (4,) -> (1, 4)\n",
        "    if quaternion.ndim == 1:\n",
        "        quaternion = quaternion.unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "    # Ensure quaternion is normalized (optional, depending on your data)\n",
        "    quaternion = kornia.geometry.quaternion.normalize_quaternion(quaternion)\n",
        "\n",
        "    # Convert to rotation matrix\n",
        "    rotation_matrix = kornia.geometry.conversions.quaternion_to_rotation_matrix(quaternion)\n",
        "\n",
        "    # Return the first (and only) rotation matrix if there was only one quaternion\n",
        "    return rotation_matrix[0] if rotation_matrix.shape[0] == 1 else rotation_matrix\n",
        "\n",
        "# Main block for computing xmin and xmax for the dataset\n",
        "if __name__ == \"__main__\":\n",
        "    dataset_path = \"/content/drive/MyDrive/KingsCollege\"  # Update this with your dataset path\n",
        "    nvm_file_path = os.path.join(dataset_path, 'reconstruction.nvm')\n",
        "\n",
        "    # Load the dataset and parse the 3D world points (w_P)\n",
        "    dataset = VisualLandmarkDataset(root_dir=dataset_path)\n",
        "    w_P = parse_nvm_file(nvm_file_path)\n",
        "\n",
        "    global_xmin = []\n",
        "    global_xmax = []\n",
        "\n",
        "    # Using tqdm for progress bar\n",
        "    for i, (image, pose) in tqdm(enumerate(dataset), total=len(dataset), desc=\"Processing Images\"):\n",
        "        translation = pose[:3].view(3, 1)\n",
        "        quaternion = pose[3:]  # Quaternion\n",
        "        c_R_w = quaternion_to_rotation_matrix(quaternion)  # Using Kornia for quaternion to rotation matrix conversion\n",
        "\n",
        "        # Compute xmin and xmax for this image\n",
        "        xmin, xmax = compute_xmin_xmax(w_P, c_R_w, translation)\n",
        "\n",
        "        global_xmin.append(xmin)\n",
        "        global_xmax.append(xmax)\n",
        "\n",
        "    # Compute global xmin and xmax for the dataset\n",
        "    global_xmin = torch.min(torch.tensor(global_xmin))\n",
        "    global_xmax = torch.max(torch.tensor(global_xmax))\n",
        "\n",
        "    print(f\"Global xmin: {global_xmin.item()}\")\n",
        "    print(f\"Global xmax: {global_xmax.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezz6SOwwRJ-O",
        "outputId": "91498ef8-b59f-4d10-babc-8401494ff44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 1563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-cbf3865a3fba>:88: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  return torch.tensor(scene_coordinates, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping invalid point on line 173480: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images: 100%|██████████| 1563/1563 [31:15<00:00,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global xmin: 2.0560340881347656\n",
            "Global xmax: 130.1615447998047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function"
      ],
      "metadata": {
        "id": "3iM3OvkU5uWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalHomographyLoss(torch.nn.Module):\n",
        "    def __init__(self, xmin, xmax, device='cpu'):\n",
        "        super().__init__()\n",
        "        xmin = torch.tensor(xmin, dtype=torch.float32, device=device)\n",
        "        xmax = torch.tensor(xmax, dtype=torch.float32, device=device)\n",
        "        self.B_weight = torch.log(xmin / xmax) / (xmax - xmin)\n",
        "        self.C_weight = xmin * xmax\n",
        "        self.c_n = torch.tensor([0, 0, -1], dtype=torch.float32, device=device).view(3, 1)\n",
        "        self.eye = torch.eye(3, device=device)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        A, B, C = compute_ABC(batch['w_t_c'], batch['c_R_w'], batch['w_t_chat'], batch['chat_R_w'], self.c_n, self.eye)\n",
        "        error = A + B * self.B_weight + C / self.C_weight\n",
        "        error = error.diagonal(dim1=1, dim2=2).sum(dim=1).mean()\n",
        "        return error\n",
        "\n",
        "# Compute A, B, and C matrices for homography-based error\n",
        "def compute_ABC(w_t_c, c_R_w, w_t_chat, chat_R_w, c_n, eye):\n",
        "    w_t_c = w_t_c.float()\n",
        "    c_R_w = c_R_w.float()\n",
        "    w_t_chat = w_t_chat.float()\n",
        "    chat_R_w = chat_R_w.float()\n",
        "    c_n = c_n.float()\n",
        "    eye = eye.float()\n",
        "\n",
        "    chat_t_c = chat_R_w @ (w_t_c - w_t_chat)\n",
        "    chat_R_c = chat_R_w @ c_R_w.transpose(1, 2)\n",
        "\n",
        "    A = eye - chat_R_c\n",
        "    C = c_n @ chat_t_c.transpose(1, 2)\n",
        "    B = C @ A\n",
        "    A = A @ A.transpose(1, 2)\n",
        "    B = B + B.transpose(1, 2)\n",
        "    C = C @ C.transpose(1, 2)\n",
        "\n",
        "    return A, B, C"
      ],
      "metadata": {
        "id": "UTrljkE2k1PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "id": "cev322Mw5_OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VisualLandmarkDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.gt_data = self._load_ground_truth()\n",
        "        self.samples = self._load_samples()\n",
        "\n",
        "    def _load_ground_truth(self):\n",
        "        gt_path = os.path.join(self.root_dir, 'GT.txt')\n",
        "        gt_data = {}\n",
        "        with open(gt_path, 'r') as f:\n",
        "            lines = f.readlines()[2:]  # Skip the first two lines (header)\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) < 8:\n",
        "                    continue\n",
        "                image_path = parts[0]\n",
        "                pose = np.array([float(x) for x in parts[1:]])  # Includes [X Y Z W P Q R]\n",
        "                gt_data[os.path.normpath(image_path)] = pose\n",
        "        return gt_data\n",
        "\n",
        "    def _load_samples(self):\n",
        "        samples = []\n",
        "        for seq_folder in os.listdir(self.root_dir):\n",
        "            seq_path = os.path.join(self.root_dir, seq_folder)\n",
        "            if os.path.isdir(seq_path):\n",
        "                image_files = sorted([f for f in os.listdir(seq_path) if f.endswith('.png')])\n",
        "                for image_file in image_files:\n",
        "                    image_path = os.path.join(seq_folder, image_file)\n",
        "                    norm_image_path = os.path.normpath(image_path)\n",
        "                    if norm_image_path in self.gt_data:\n",
        "                        full_image_path = os.path.join(self.root_dir, image_path)\n",
        "                        samples.append((full_image_path, self.gt_data[norm_image_path]))\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self.samples):\n",
        "            raise IndexError(f\"Index {idx} out of bounds for samples of size {len(self.samples)}\")\n",
        "        color_path, pose = self.samples[idx]\n",
        "        color_image = cv2.imread(color_path, cv2.IMREAD_COLOR)\n",
        "        translation = pose[:3]  # [X, Y, Z]\n",
        "        quaternion = pose[3:]   # [W, P, Q, R] (quaternion)\n",
        "        pose_matrix = np.concatenate([translation, quaternion])\n",
        "        if self.transform:\n",
        "            color_image = self.transform(color_image)\n",
        "        return color_image, torch.tensor(pose_matrix, dtype=torch.float32)\n",
        "\n",
        "# Define the transformation for the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n"
      ],
      "metadata": {
        "id": "CzZ1O6QMk17B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CoHAtNet Model"
      ],
      "metadata": {
        "id": "6u6-xXA_6DAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "\n",
        "def conv_3x3_bn(inp, oup, image_size, downsample=False):\n",
        "    stride = 1 if downsample == False else 2\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        nn.GELU()\n",
        "    )\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn, norm):\n",
        "        super().__init__()\n",
        "        self.norm = norm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "\n",
        "class SE(nn.Module):\n",
        "    def __init__(self, inp, oup, expansion=0.25):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(oup, int(inp * expansion), bias=False),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(int(inp * expansion), oup, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class MBConv(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, downsample=False, expansion=4):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample\n",
        "        stride = 1 if self.downsample == False else 2\n",
        "        hidden_dim = int(inp * expansion)\n",
        "\n",
        "        if self.downsample:\n",
        "            self.pool = nn.MaxPool2d(3, 2, 1)\n",
        "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "\n",
        "        if expansion == 1:\n",
        "            self.conv = nn.Sequential(\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride,\n",
        "                          1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pw\n",
        "                # down-sample in the first conv\n",
        "                nn.Conv2d(inp, hidden_dim, 1, stride, 0, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, 1, 1,\n",
        "                          groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                SE(inp, hidden_dim),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "\n",
        "        self.conv = PreNorm(inp, self.conv, nn.BatchNorm2d)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.downsample:\n",
        "            return self.proj(self.pool(x)) + self.conv(x)\n",
        "        else:\n",
        "            return x + self.conv(x)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == inp)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        # parameter table of relative position bias\n",
        "        self.relative_bias_table = nn.Parameter(\n",
        "            torch.zeros((2 * self.ih - 1) * (2 * self.iw - 1), heads))\n",
        "\n",
        "        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))\n",
        "        coords = torch.flatten(torch.stack(coords), 1)\n",
        "        relative_coords = coords[:, :, None] - coords[:, None, :]\n",
        "\n",
        "        relative_coords[0] += self.ih - 1\n",
        "        relative_coords[1] += self.iw - 1\n",
        "        relative_coords[0] *= 2 * self.iw - 1\n",
        "        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n",
        "        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n",
        "        self.register_buffer(\"relative_index\", relative_index)\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)\n",
        "        self.to_qkv = nn.Linear(inp, inner_dim * 3, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, oup),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = map(lambda t: rearrange(\n",
        "            t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        # Use \"gather\" for more efficiency on GPUs\n",
        "        relative_bias = self.relative_bias_table.gather(\n",
        "            0, self.relative_index.repeat(1, self.heads))\n",
        "        relative_bias = rearrange(\n",
        "            relative_bias, '(h w) c -> 1 c h w', h=self.ih*self.iw, w=self.ih*self.iw)\n",
        "        dots = dots + relative_bias\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out = self.to_out(out)\n",
        "        return out\n",
        "\n",
        "class HAttention(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == inp)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        # parameter table of relative position bias\n",
        "        self.relative_bias_table = nn.Parameter(\n",
        "            torch.zeros((2 * self.ih - 1) * (2 * self.iw - 1), heads))\n",
        "\n",
        "        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))\n",
        "        coords = torch.flatten(torch.stack(coords), 1)\n",
        "        relative_coords = coords[:, :, None] - coords[:, None, :]\n",
        "\n",
        "        relative_coords[0] += self.ih - 1\n",
        "        relative_coords[1] += self.iw - 1\n",
        "        relative_coords[0] *= 2 * self.iw - 1\n",
        "        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n",
        "        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n",
        "        self.register_buffer(\"relative_index\", relative_index)\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)\n",
        "        self.to_qk = nn.Linear(inp, inner_dim * 2, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "#            nn.Linear(inner_dim, oup),\n",
        "            nn.Linear(oup, oup),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, mbconv):\n",
        "        qk = self.to_qk(x).chunk(2, dim=-1)\n",
        "        q, k = map(lambda t: rearrange(\n",
        "            t, 'b n (h d) -> b h n d', h=self.heads), qk)\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        # Use \"gather\" for more efficiency on GPUs\n",
        "        relative_bias = self.relative_bias_table.gather(\n",
        "            0, self.relative_index.repeat(1, self.heads))\n",
        "        relative_bias = rearrange(\n",
        "            relative_bias, '(h w) c -> 1 c h w', h=self.ih*self.iw, w=self.ih*self.iw)\n",
        "        dots = dots + relative_bias\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "        v = rearrange(mbconv, 'b c ih iw -> b (ih iw) c')\n",
        "        v = rearrange(v, 'b n (h c) -> b h n c', h=self.heads)\n",
        "\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out = self.to_out(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, downsample=False, dropout=0.):\n",
        "        super().__init__()\n",
        "        hidden_dim = int(inp * 4)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "        self.downsample = downsample\n",
        "\n",
        "        if self.downsample:\n",
        "            self.pool1 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.pool2 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "\n",
        "        self.attn = Attention(inp, oup, image_size, heads, dim_head, dropout)\n",
        "        self.ff = FeedForward(oup, hidden_dim, dropout)\n",
        "\n",
        "        self.attn = nn.Sequential(\n",
        "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
        "            PreNorm(inp, self.attn, nn.LayerNorm),\n",
        "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "        )\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
        "            PreNorm(oup, self.ff, nn.LayerNorm),\n",
        "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.downsample:\n",
        "            x = self.proj(self.pool1(x)) + self.attn(self.pool2(x))\n",
        "        else:\n",
        "            x = x + self.attn(x)\n",
        "        x = x + self.ff(x)\n",
        "        return x\n",
        "\n",
        "class HTransformer(nn.Module):\n",
        "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, downsample=False, dropout=0.):\n",
        "        super().__init__()\n",
        "        hidden_dim = int(inp * 4)\n",
        "\n",
        "        self.ih, self.iw = image_size\n",
        "        self.downsample = downsample\n",
        "        self.layer_norm = nn.LayerNorm(inp)\n",
        "        self.MBConv = MBConv(inp, oup, image_size, downsample)\n",
        "\n",
        "        if self.downsample:\n",
        "            self.pool1 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.pool2 = nn.MaxPool2d(3, 2, 1)\n",
        "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
        "\n",
        "        self.attn = HAttention(inp, oup, image_size, heads, dim_head, dropout)\n",
        "        self.ff = FeedForward(oup, hidden_dim, dropout)\n",
        "\n",
        "#        self.attn = nn.Sequential(\n",
        "#            Rearrange('b c ih iw -> b (ih iw) c'),\n",
        "#            PreNorm(inp, self.attn, nn.LayerNorm),\n",
        "#            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "#        )\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
        "            PreNorm(oup, self.ff, nn.LayerNorm),\n",
        "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        mbconv = self.MBConv(x)\n",
        "        if self.downsample:\n",
        "            pool1 = self.pool2(x)\n",
        "            pool1 = rearrange(pool1, 'b c ih iw -> b (ih iw) c')\n",
        "            norm1 = self.layer_norm(pool1)\n",
        "            attn1 = self.attn(norm1, mbconv)\n",
        "            attn1 = rearrange(attn1, 'b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "            out1 = self.proj(self.pool1(x)) + attn1\n",
        "#            x = self.proj(self.pool1(x)) + self.attn(self.pool2(x), y)\n",
        "        else:\n",
        "            xx = rearrange(x, 'b c ih iw -> b (ih iw) c')\n",
        "            norm1 = self.layer_norm(xx)\n",
        "            attn1 = self.attn(norm1, mbconv)\n",
        "            attn1 = rearrange(attn1, 'b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
        "            out1 = x + attn1\n",
        "\n",
        "#            x = x + self.attn(x,y)\n",
        "        x = out1 + self.ff(out1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CoHAtNet(nn.Module):\n",
        "    def __init__(self, image_size, in_channels, num_blocks, channels, num_classes=1000, block_types=['C', 'C', 'H', 'H']):\n",
        "        super().__init__()\n",
        "        ih, iw = image_size\n",
        "        block = {'C': MBConv, 'T': Transformer, 'H': HTransformer}\n",
        "\n",
        "        self.s0 = self._make_layer(\n",
        "            conv_3x3_bn, in_channels, channels[0], num_blocks[0], (ih // 2, iw // 2))\n",
        "        self.s1 = self._make_layer(\n",
        "            block[block_types[0]], channels[0], channels[1], num_blocks[1], (ih // 4, iw // 4))\n",
        "        self.s2 = self._make_layer(\n",
        "            block[block_types[1]], channels[1], channels[2], num_blocks[2], (ih // 8, iw // 8))\n",
        "        self.s3 = self._make_layer(\n",
        "            block[block_types[2]], channels[2], channels[3], num_blocks[3], (ih // 16, iw // 16))\n",
        "        self.s4 = self._make_layer(\n",
        "            block[block_types[3]], channels[3], channels[4], num_blocks[4], (ih // 32, iw // 32))\n",
        "\n",
        "        self.pool = nn.AvgPool2d(ih // 32, 1)\n",
        "        hidden_dim = 1024\n",
        "        self.fc1 = nn.Linear(channels[-1] * 2, hidden_dim)\n",
        "        self.relu = nn.ReLU()  # Activation function between dense layers\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)  # Another dense layer\n",
        "        self.fc3 = nn.Linear(hidden_dim // 2, 7)  # Final output layer adjusted to target size (e.g., 6 for 6DoF pose)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.s0(x)\n",
        "        x = self.s1(x)\n",
        "        x = self.s2(x)\n",
        "        x = self.s3(x)\n",
        "        x = self.s4(x)\n",
        "\n",
        "        x = self.pool(x).view(-1, x.shape[1])\n",
        "\n",
        "        # Concatenation might be necessary depending on model specifics; assuming you meant *2 in channels\n",
        "        x = torch.cat((x, x), dim=1)  # Concatenation for expanding feature dimension\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, inp, oup, depth, image_size):\n",
        "        layers = nn.ModuleList([])\n",
        "        for i in range(depth):\n",
        "            if i == 0:\n",
        "                layers.append(block(inp, oup, image_size, downsample=True))\n",
        "            else:\n",
        "                layers.append(block(oup, oup, image_size))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def cohatnet_0():\n",
        "    num_blocks = [2, 2, 3, 5, 2]            # L\n",
        "    channels = [64, 96, 192, 384, 768]      # D\n",
        "    return CoHAtNet((256, 256), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def cohatnet_1():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [64, 96, 192, 384, 768]      # D\n",
        "    return CoHAtNet((256, 256), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def cohatnet_2():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [128, 128, 256, 512, 1024]   # D\n",
        "    return CoHAtNet((256, 256), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def cohatnet_3():\n",
        "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
        "    channels = [192, 192, 384, 768, 1536]   # D\n",
        "    return CoHAtNet((256, 256), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def cohatnet_4():\n",
        "    num_blocks = [2, 2, 12, 28, 2]          # L\n",
        "    channels = [192, 192, 384, 768, 1536]   # D\n",
        "    return CoHAtNet((256, 256), 3, num_blocks, channels, num_classes=1000)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    img = torch.randn(1, 3, 256, 256)\n",
        "\n",
        "    net = cohatnet_0()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = cohatnet_1()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = cohatnet_2()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = cohatnet_3()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n",
        "\n",
        "    net = cohatnet_4()\n",
        "    out = net(img)\n",
        "    print(out.shape, count_parameters(net))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgBq1X2flMCb",
        "outputId": "d7184581-1791-4108-e298-da1fcc87a33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 7]) 34337023\n",
            "torch.Size([1, 7]) 62756935\n",
            "torch.Size([1, 7]) 108877575\n",
            "torch.Size([1, 7]) 238862151\n",
            "torch.Size([1, 7]) 411054007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "K_4Z7GzZ6I9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with Global Homography Loss\n",
        "if __name__ == '__main__':\n",
        "    root_dir = '/content/drive/MyDrive/KingsCollege'\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    dataset = VisualLandmarkDataset(root_dir=root_dir, transform=transform)\n",
        "\n",
        "    # Instantiate Global Homography Loss with precomputed xmin and xmax\n",
        "    global_loss_fn = GlobalHomographyLoss(xmin=2.05, xmax=130.16, device=device)\n",
        "\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    num_epochs = 100\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f'Fold {fold + 1}')\n",
        "\n",
        "        train_sampler = SubsetRandomSampler(train_idx)\n",
        "        val_sampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "        train_loader = DataLoader(dataset, batch_size=16, sampler=train_sampler, num_workers=4)\n",
        "        val_loader = DataLoader(dataset, batch_size=16, sampler=val_sampler, num_workers=4)\n",
        "\n",
        "        model = cohatnet_0().to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=4, factor=0.1)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "\n",
        "            for color_images, poses in tqdm(train_loader):\n",
        "                color_images, poses = color_images.to(device), poses.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(color_images)\n",
        "\n",
        "                pred_translation = outputs[:, :3]\n",
        "                pred_quaternion = outputs[:, 3:]\n",
        "                pred_quaternion = F.normalize(pred_quaternion, p=2, dim=-1)\n",
        "\n",
        "                # Prepare batch for loss computation\n",
        "                batch = {\n",
        "                    'w_t_c': pred_translation.unsqueeze(-1),\n",
        "                    'c_R_w': quaternion_to_rotation_matrix(pred_quaternion),  # Convert predicted quaternion to rotation matrix\n",
        "                    'w_t_chat': poses[:, :3].unsqueeze(-1),  # Ground truth translation\n",
        "                    'chat_R_w': quaternion_to_rotation_matrix(poses[:, 3:])  # Convert ground truth quaternion to rotation matrix\n",
        "                }\n",
        "\n",
        "                loss = global_loss_fn(batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "            # Validation loop\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for color_images, poses in val_loader:\n",
        "                    color_images, poses = color_images.to(device), poses.to(device)\n",
        "                    outputs = model(color_images)\n",
        "\n",
        "                    pred_translation = outputs[:, :3]\n",
        "                    pred_quaternion = outputs[:, 3:]\n",
        "                    pred_quaternion = F.normalize(pred_quaternion, p=2, dim=-1)\n",
        "\n",
        "                    batch = {\n",
        "                        'w_t_c': pred_translation.unsqueeze(-1),\n",
        "                        'c_R_w': quaternion_to_rotation_matrix(pred_quaternion),  # Convert predicted quaternion to rotation matrix\n",
        "                        'w_t_chat': poses[:, :3].unsqueeze(-1),  # Ground truth translation\n",
        "                        'chat_R_w': quaternion_to_rotation_matrix(poses[:, 3:])  # Convert ground truth quaternion to rotation matrix\n",
        "                    }\n",
        "\n",
        "                    loss = global_loss_fn(batch)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "            print(f'Epoch {epoch + 1}, Train Loss: {avg_train_loss}, Val Loss: {val_loss / len(val_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XQh5YP-7lQRu",
        "outputId": "fab1dd27-c0da-4f36-d639-0ac7cfb5c77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [08:36<00:00,  6.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 4.835632733151883, Val Loss: 4.211350810527802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train Loss: 1.572676900821396, Val Loss: 2.9313368678092955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Train Loss: 1.0168373128281365, Val Loss: 0.6819047793745995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Train Loss: 0.5966121180902554, Val Loss: 0.5787667453289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train Loss: 0.719934151519703, Val Loss: 0.7713652364909649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Train Loss: 0.5105404842503464, Val Loss: 0.6938246741890908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Train Loss: 0.5378586735717857, Val Loss: 0.239171876758337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Train Loss: 0.5680619420695908, Val Loss: 1.1625386759638787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Train Loss: 0.4106814161508898, Val Loss: 0.28597305417060853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 0.25692207535988165, Val Loss: 0.6065299823880196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Train Loss: 0.4624419523568093, Val Loss: 0.28082291334867476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Train Loss: 0.21765380343304405, Val Loss: 0.16736471578478812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Train Loss: 0.16312933086028583, Val Loss: 0.23454580195248126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Train Loss: 0.14159141542224946, Val Loss: 0.1498720146715641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Train Loss: 0.11042192318960081, Val Loss: 0.22131731137633323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Train Loss: 0.11092270953179914, Val Loss: 0.14619202092289924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Train Loss: 0.12014019475141659, Val Loss: 0.18386728465557098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Train Loss: 0.10477848233112806, Val Loss: 0.13093410357832908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Train Loss: 0.10357132591778719, Val Loss: 0.14263443946838378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Train Loss: 0.07258059280111065, Val Loss: 0.126938870921731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Train Loss: 0.06122600030201145, Val Loss: 0.10365483164787292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Train Loss: 0.06136359033893935, Val Loss: 0.09086566083133221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Train Loss: 0.06006005901513221, Val Loss: 0.0801632234826684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Train Loss: 0.053779547067382666, Val Loss: 0.12270715162158012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Train Loss: 0.05011114588926865, Val Loss: 0.10093873925507069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Train Loss: 0.044287755213017706, Val Loss: 0.10475637391209602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Train Loss: 0.06037984845004504, Val Loss: 0.1534708734601736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Train Loss: 0.0853772972344975, Val Loss: 0.08372964654117823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Train Loss: 0.030196519427095787, Val Loss: 0.0722780266776681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Train Loss: 0.0264129209674046, Val Loss: 0.07779307514429093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31, Train Loss: 0.02446314529810525, Val Loss: 0.07179590873420238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32, Train Loss: 0.02532257559367373, Val Loss: 0.07543272124603391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Train Loss: 0.02477998139124505, Val Loss: 0.0714752845466137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34, Train Loss: 0.023567731150343448, Val Loss: 0.0716950163245201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35, Train Loss: 0.0214528289352414, Val Loss: 0.0769429586827755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36, Train Loss: 0.02309371192668435, Val Loss: 0.06966219237074256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37, Train Loss: 0.03188523413212616, Val Loss: 0.07284466437995434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38, Train Loss: 0.024483646407629116, Val Loss: 0.07195181399583817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39, Train Loss: 0.020926999399745013, Val Loss: 0.06744818575680256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40, Train Loss: 0.019193864462873602, Val Loss: 0.07292891778051853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41, Train Loss: 0.02162107523483566, Val Loss: 0.06904572965577245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42, Train Loss: 0.02024312957508277, Val Loss: 0.07505382997915148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43, Train Loss: 0.018205066494455066, Val Loss: 0.07239061426371336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44, Train Loss: 0.01760320634215693, Val Loss: 0.06890367409214378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Train Loss: 0.021655154414474964, Val Loss: 0.06769340103492141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46, Train Loss: 0.021572068044797905, Val Loss: 0.07911416385322809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47, Train Loss: 0.01628580074050004, Val Loss: 0.07367403842508793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48, Train Loss: 0.016613805507415834, Val Loss: 0.0711928667500615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Train Loss: 0.01613051567486004, Val Loss: 0.07048201030120253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Train Loss: 0.016875828934621206, Val Loss: 0.07085371073335409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51, Train Loss: 0.01529378851852085, Val Loss: 0.06846006028354168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52, Train Loss: 0.017724091664569664, Val Loss: 0.07443253006786107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53, Train Loss: 0.014625633194382433, Val Loss: 0.07176572214812041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54, Train Loss: 0.018483074452680878, Val Loss: 0.07991176322102547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:21<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55, Train Loss: 0.015324291655251497, Val Loss: 0.0692306550219655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56, Train Loss: 0.016445355755100144, Val Loss: 0.07122256709262728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57, Train Loss: 0.019737895035856885, Val Loss: 0.0706227608025074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58, Train Loss: 0.015696093552050334, Val Loss: 0.07164405100047588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59, Train Loss: 0.015127163804784606, Val Loss: 0.06702355043962598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60, Train Loss: 0.01717010413921332, Val Loss: 0.07465478535741568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61, Train Loss: 0.015420476894212675, Val Loss: 0.07536697881296277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62, Train Loss: 0.01585799883579529, Val Loss: 0.069304427690804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63, Train Loss: 0.015168643356124056, Val Loss: 0.06911253994330764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64, Train Loss: 0.015124036140645607, Val Loss: 0.066402546223253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65, Train Loss: 0.016675963261035046, Val Loss: 0.07600725330412388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66, Train Loss: 0.015021062526804737, Val Loss: 0.06978756533935666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67, Train Loss: 0.022208596674041656, Val Loss: 0.06655892049893737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68, Train Loss: 0.01740117537305702, Val Loss: 0.07361576408147812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69, Train Loss: 0.015212656193283162, Val Loss: 0.07337656477466226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70, Train Loss: 0.024038091702740405, Val Loss: 0.07771991901099681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71, Train Loss: 0.01685760018734049, Val Loss: 0.07431906871497632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72, Train Loss: 0.014638231513149377, Val Loss: 0.07280220119282603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73, Train Loss: 0.015398125718288783, Val Loss: 0.071544589381665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74, Train Loss: 0.015011802068145215, Val Loss: 0.07265951875597239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75, Train Loss: 0.016695757903441598, Val Loss: 0.08107489831745625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76, Train Loss: 0.016794908143391338, Val Loss: 0.07337910477072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77, Train Loss: 0.017702955516833294, Val Loss: 0.07591576017439365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78, Train Loss: 0.015613104629365705, Val Loss: 0.06971172224730253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79, Train Loss: 0.015197464147040362, Val Loss: 0.06937008025124669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80, Train Loss: 0.02184190057642475, Val Loss: 0.07107782857492566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81, Train Loss: 0.015682744840749458, Val Loss: 0.06709403190761805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82, Train Loss: 0.015400761820941786, Val Loss: 0.06998985819518566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83, Train Loss: 0.015625430271029472, Val Loss: 0.0727739742025733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84, Train Loss: 0.016064146610236245, Val Loss: 0.07037071045488119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85, Train Loss: 0.017154627821490735, Val Loss: 0.07355728764086962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86, Train Loss: 0.01734916732611158, Val Loss: 0.0715199408121407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87, Train Loss: 0.015830826020174767, Val Loss: 0.0696901310235262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88, Train Loss: 0.015766976059331923, Val Loss: 0.0679551638662815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89, Train Loss: 0.029956351971560265, Val Loss: 0.06588344564661383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90, Train Loss: 0.016500571601187126, Val Loss: 0.06914085438475012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91, Train Loss: 0.01687917746367711, Val Loss: 0.06877485122531653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92, Train Loss: 0.016843125430419097, Val Loss: 0.07671053204685449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93, Train Loss: 0.01581092821905696, Val Loss: 0.07210729848593474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94, Train Loss: 0.015126268108245692, Val Loss: 0.08454523421823978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95, Train Loss: 0.01535173609286924, Val Loss: 0.06882009543478489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96, Train Loss: 0.017129340244433546, Val Loss: 0.07018350306898355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97, Train Loss: 0.01584874200222047, Val Loss: 0.07109872214496135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98, Train Loss: 0.014908612169372507, Val Loss: 0.06803834112361073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99, Train Loss: 0.015532991931408266, Val Loss: 0.06698701893910766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100, Train Loss: 0.017549244121094293, Val Loss: 0.07387749096378685\n",
            "Fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 4.65821190725399, Val Loss: 2.4290404200553892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train Loss: 1.6636644733857504, Val Loss: 2.1821664392948152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Train Loss: 1.1161381213725368, Val Loss: 0.6460889011621476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Train Loss: 0.7347933282203312, Val Loss: 0.6696714602410794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train Loss: 1.8006245416553714, Val Loss: 1.2479082942008972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Train Loss: 0.8702359180661696, Val Loss: 0.40766422376036643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Train Loss: 0.6652618605124799, Val Loss: 0.28969397246837614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Train Loss: 0.3571737791541256, Val Loss: 0.354629073292017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Train Loss: 0.3080367526110214, Val Loss: 0.2707753129303455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 0.2939045507507988, Val Loss: 0.4594097249209881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Train Loss: 0.2819042139792744, Val Loss: 0.24419419839978218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Train Loss: 0.2049806741408155, Val Loss: 0.17653886526823043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Train Loss: 0.16590441122085234, Val Loss: 0.27243184223771094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Train Loss: 0.1641909213194364, Val Loss: 0.20791743472218513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Train Loss: 0.13546907887617243, Val Loss: 0.2268209882080555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:21<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Train Loss: 0.11013925924331328, Val Loss: 0.14466933868825435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Train Loss: 0.11490315566711788, Val Loss: 0.399067759513855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Train Loss: 0.2649229859249501, Val Loss: 0.2122339803725481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Train Loss: 0.15625824604796457, Val Loss: 0.4619454324245453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Train Loss: 0.8984631166050706, Val Loss: 0.5170629099011421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:21<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Train Loss: 0.26439049368417716, Val Loss: 0.30974554605782034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Train Loss: 0.14553517145635206, Val Loss: 0.1560083631426096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Train Loss: 0.1395242646147933, Val Loss: 0.16265131160616875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Train Loss: 0.12061783020632176, Val Loss: 0.14109850451350212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Train Loss: 0.10340696752448625, Val Loss: 0.15453064497560262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Train Loss: 0.10157929898440084, Val Loss: 0.13551596459001303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Train Loss: 0.09576884228028829, Val Loss: 0.12778357677161695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Train Loss: 0.10424991715935213, Val Loss: 0.17008389793336393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:20<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Train Loss: 0.09129343526084212, Val Loss: 0.13800155483186244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 68/79 [00:18<00:02,  3.67it/s]\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-9-378ce34f2717>\", line 31, in <cell line: 2>\n",
            "    for color_images, poses in tqdm(train_loader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1327, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1293, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1131, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 113, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 424, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 878, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 396, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, strict, {})\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 431, in _joinrealpath\n",
            "    st = os.lstat(newpath)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-378ce34f2717>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcolor_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mcolor_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    }
  ]
}